"use client";

import type { StreamingProvider, BotResponse } from "../chatbot/types/ChatbotTypes";
import { KORSHI_SYSTEM_PROMPT } from "./systemPrompt";

// ВАЖНО: В реальном проекте ключ лучше выносить в .env
const GROQ_API_KEY = "ТВОЙ_КЛЮЧ_GROQ"; 

export function createGroqBot(): StreamingProvider {
  async function* stream(prompt: string) {
    try {
      const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${GROQ_API_KEY}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "llama-3.3-70b-versatile", // Или "llama3-8b-8192" для еще большей скорости
          messages: [
            { role: "system", content: KORSHI_SYSTEM_PROMPT },
            { role: "user", content: prompt }
          ],
          temperature: 0.7,
          max_tokens: 500,
          stream: true, // Включаем стриминг
        }),
      });

      if (!response.ok) throw new Error("Groq API Error");

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();

      if (!reader) return;

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split("\n");

        for (const line of lines) {
          if (line.startsWith("data: ") && line !== "data: [DONE]") {
            try {
              const data = JSON.parse(line.slice(6));
              const content = data.choices[0]?.delta?.content;
              if (content) yield content;
            } catch (e) {
              continue;
            }
          }
        }
      }
    } catch (error) {
      console.error("Groq Stream Error:", error);
      yield "Извините, произошла ошибка соединения. Попробуйте позже.";
    }
  }

  async function send(prompt: string): Promise<BotResponse> {
    let fullText = "";
    for await (const chunk of stream(prompt)) {
      fullText += chunk;
    }
    return {
      text: fullText.trim(),
      intent: "llm_generated",
      confidence: 1.0
    };
  }

  return { send, stream };
}